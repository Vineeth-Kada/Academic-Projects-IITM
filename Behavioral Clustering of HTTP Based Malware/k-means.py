from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from itertools import product
import pandas as pd
import numpy as np
from sklearn import decomposition
import copy
import os
from sklearn.cluster import KMeans
import scipy.cluster.hierarchy as sch
from sklearn.cluster import AgglomerativeClustering
import sys

# obtain the data
df = pd.read_csv('Network_clean_backdoor_downloader_v2.csv', index_col=0)

sni_statistics = ['sni_digitratio', 'sni_alpharatio', 'sni_specialcharratio', 'sni_caseratio', 'sni_vowelchangeratio']
dns_statistics = ['dns_nxdomain_digitratio', 'dns_nxdomain_alpharatio', 'dns_nxdomain_specialcharratio', 'dns_nxdomain_caseratio', 'dns_nxdomain_vowelchangeratio', 'dns_success_digitratio', 'dns_success_alpharatio', 'dns_success_specialcharratio', 'dns_success_caseratio', 'dns_success_vowelchangeratio']

df = df.dropna(subset=sni_statistics + dns_statistics)

## Malware-Family prediction accuracies
flow_statistics = ['number_of_flows', 'average_of_duration', 'standard_deviation_duration', 'percent_of_standard_deviation_duration', 'total_size_of_flows_orig', 'total_size_of_flows_resp', 'ratio_of_sizes', 'percent_of_established_states', 'inbound_pckts', 'outbound_pckts', 'periodicity_average', 'periodicity_standart_deviation']
url_statistics = ['url_path_length', 'number_of_URL_query_parameters', 'number_of_url_flows', 'number_of_downloaded_bytes', 'number_of_uploaded_bytes', 'urldigitratio', 'urlalpharatio', 'urlspecialcharratio', 'urlcaseratio', 'urlvowelchangeratio']
certificate_statistics = ['ssl_ratio', 'average_public_key', 'tls_version_ratio', 'average_of_certificate_length', 'standart_deviation_cert_length', 'is_valid_certificate_during_capture', 'amount_diff_certificates', 'number_of_domains_in_certificate', 'certificate_ratio', 'number_of_certificate_path', 'x509_ssl_ratio', 'SNI_ssl_ratio', 'self_signed_ratio']
filename_statistics = ['filename_digitratio', 'filename_alpharatio', 'filename_specialcharratio', 'filename_vowelchangeratio']
hostname_statistics = ['hostname_digitratio', 'hostname_alpharatio', 'hostname_specialcharratio', 'hostname_vowelchangeratio']
sni_statistics = ['sni_digitratio', 'sni_alpharatio', 'sni_specialcharratio', 'sni_vowelchangeratio']
dns_statistics = ['dns_nxdomain_digitratio', 'dns_nxdomain_alpharatio', 'dns_nxdomain_specialcharratio', 'dns_nxdomain_vowelchangeratio', 'dns_success_alpharatio', 'dns_success_specialcharratio', 'dns_success_vowelchangeratio']

cols = flow_statistics + url_statistics + certificate_statistics + filename_statistics + hostname_statistics + sni_statistics + dns_statistics
all_cols = flow_statistics + url_statistics + certificate_statistics + filename_statistics + hostname_statistics + sni_statistics + dns_statistics

# X = df[cols].copy()
# y = df.family.astype('category').cat.codes

# X[cols] = X[cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

# # train test split 20%
# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# # Fit an SVM classifier on the training data
# from sklearn import svm
# clf = svm.SVC(kernel='rbf')
# clf.fit(X_train, y_train)

# # test accuracy
# print('SVM Classifier Accuracy:', clf.score(X_test, y_test))

# # Fit an ANN classifier on the training data
# from sklearn.neural_network import MLPClassifier
# clf = MLPClassifier(activation = 'logistic', hidden_layer_sizes=(128, 64), max_iter = 1000, random_state=1, tol = 10**-5)
# clf.fit('FFNN Classifier Accuracy', X_train, y_train)

# # test accuracy
# print(clf.score(X_test, y_test))

## Chi-squared feature selection
X = df[cols].copy()
y = df.family.astype('category').cat.codes

X[cols] = X[cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

X_train, y_train = X, y

from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
X_new = SelectKBest(chi2, k = 15).fit(X_train, y_train)

new_cols = X_new.get_support(indices=True)
X_new = X_train.iloc[:,new_cols]
chi_square_features = X_new.columns

# Elbow plot

import matplotlib.pyplot as plt
sum_of_squared_distances = []
K = range(1, 11)
for num_clusters in K:
    # Create a KMeans instance with k clusters: model
    model = KMeans(n_clusters=num_clusters)
    # Fit model to samples
    model.fit(df[chi_square_features])
    # Append the sum of squared distances of samples to the list
    sum_of_squared_distances.append(model.inertia_)

plt.plot(K,sum_of_squared_distances,'bx-')
plt.xlabel('Values of K') 
plt.ylabel('Sum of squared distances/Inertia')
plt.title('Elbow Method For Optimal k')
plt.savefig('elbow_method_for_optimal_k.svg')

# cluster the data points
num_clusters = 4
kmeans = KMeans(n_clusters=num_clusters)
kmeans = kmeans.fit(df[chi_square_features])

# Save the labels
df = df.assign(labels=kmeans.labels_)

# set sys.out to a file
sys.stdout = open('kmeans_clusters.txt', 'w')
for cluster in range(num_clusters):
    cluster_df = df[df['labels'] == cluster]
    print(cluster, len(cluster_df))
    Malware_percent = 100*len(cluster_df[cluster_df['binarylabel'] == 1]) / len(cluster_df)
    print('Malware Percentage:', Malware_percent)
    print(cluster_df['goal'].value_counts() / len(cluster_df))