from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from itertools import product
import pandas as pd
import numpy as np
from sklearn import decomposition
import copy
import os
from sklearn.cluster import KMeans
import scipy.cluster.hierarchy as sch
from sklearn.cluster import AgglomerativeClustering
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
from sklearn.metrics import davies_bouldin_score

# obtain the data
df = pd.read_csv('Network_clean_backdoor_downloader_v2.csv', index_col=0)


################################################################################
# STEP1: Eliminate all the features which are almost useless because they are equal to a default value most of the time
###############################################################################

# Percentage of default values like 0, NaN, -1, [] etc., in each column
per_list = []
col_list = []
good_cols = [] # Columns which has reasonable amount of data
threshold = 89 # We will ignore all features with >= threshold percent default values

for col in df.columns:
    per1 = df[col].isna().sum() / df.shape[0] * 100         # Percentage of NaN
    per2 = len(df[df[col] == '[]'])/ df.shape[0] * 100      # Percentage of empty set 
    per3 = len(df[df[col] == 0])/ df.shape[0] * 100         # Percentage of 0
    per4 = len(df[df[col] == '0'])/ df.shape[0] * 100         # Percentage of '0'
    per5 = len(df[df[col] == -1])/ df.shape[0] * 100        # Percentage of -1
    per6 = len(df[df[col] == 1])/ df.shape[0] * 100         # Percentage of 1
    per = max([per1, per2, per3, per4, per5, per6])
    per = round(per, 2)
    col_list.append(col)
    per_list.append(per)
    if(per <= threshold):
        good_cols.append(col)
per_list, col_list = zip(*sorted(zip(per_list, col_list)))

# for i in range(len(per_list)):
#     if(per_list[-i-1] <= threshold):
#         print('%20s  %.2f%s' % (col_list[-i-1],per_list[-i-1],'%'))
#         print(col_list[-i-1], per_list[-i-1])


# print(df['dns_nxdomain'].unique())
# print(df['goal'].value_counts())
# print(good_cols)

non_empty_cols = []
# We have to ignore these columns.
cols_ignore = ['binarylabel', 'goal', 'family_label', 'family', '#Src_IP', 'hash', 'sportcounts']

for col in good_cols:
    if(col not in cols_ignore):
        non_empty_cols.append(col)

# print(non_empty_cols)
df = df.dropna(subset=non_empty_cols)

################################################################################
# STEP2: Chi - Square analysis for feature selection
###############################################################################

# Chi Square Analysis Begins
X = df[non_empty_cols].copy()
y = df.family_label.astype('category').cat.codes

# Doing normalisation
X[non_empty_cols] = X[non_empty_cols].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

X_train, y_train = X, y
X_new = SelectKBest(chi2, k = 6).fit(X_train, y_train) # Takingn 6 best features.
new_cols = X_new.get_support(indices=True)
X_new = X_train.iloc[:,new_cols]
chi_square_features = X_new.columns

# print(chi_square_features)


################################################################################
# STEP3: We have to apply a clustering algorithm
###############################################################################

###############################################################################
# Algorithm1: Single Linkage Hierarchical Clustering
###############################################################################

cols_to_norm = chi_square_features
df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

# DB Index Plot
print('Generating DB Index Plot....')
X_plot, Y_plot = [], []
for num_clusters in range(5, 30):
    cluster = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='single')
    cluster.fit_predict(df[cols_to_norm])
    df = df.assign(labels=cluster.labels_)
    
    X_plot.append(num_clusters)
    score = davies_bouldin_score(df[cols_to_norm].copy(), cluster.labels_)
    print('Processed', num_clusters, 'clusters.')
    Y_plot.append(score)
plt.clf(); plt.plot(X_plot, Y_plot)
plt.ylabel('DB Index'); plt.xlabel('No. of clusters')
plt.savefig('6_chi_single_dbindex.svg')
print('Generated DB Index Plot.')
Y_plot_sorted, X_plot_sorted  = zip(*sorted(zip(Y_plot, X_plot)))
print('Optimal Clusters:', X_plot_sorted[0])

# For K = 18
for num_clusters in range(18, 19):
    cluster = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='single')
    cluster.fit_predict(df[cols_to_norm])
    df = df.assign(labels=cluster.labels_)

    correct, total = 0, 0
    for cluster in range(num_clusters):
        cluster_df = df[df['labels'] == cluster]
        print('Cluster #', cluster, ', No of items in cluster:', len(cluster_df))

        Malware_percent = 100*len(cluster_df[cluster_df['binarylabel'] == 1]) / len(cluster_df)
        print('Malware Percentage:', Malware_percent)

        if(Malware_percent >= 50):
            correct += len(cluster_df[cluster_df['binarylabel'] == 1])
        else:
            correct += len(cluster_df[cluster_df['binarylabel'] == 0])
        total += len(cluster_df)
        
    for s in ['family', 'goal']:
        fig = plt.figure(figsize=(12, 6))
        cnt = 0
        for cluster in [0, 3, 8]:
            cluster_df = df[df['labels'] == cluster]
            if(num_clusters == 18): ax = fig.add_subplot(1, 3, cnt + 1)
            cnt += 1
            ax = cluster_df[s].value_counts().plot(kind='pie', legend = True, labels = None, fontsize = 10)
            ax.legend(labels = cluster_df[s].value_counts().index, fontsize = 7)
        fig.savefig('chi_6_single_' + s + str(num_clusters) + '.svg')
        plt.clf()

    print("ACCURACY (MALWARE vs. NORMAL): ", 100 * correct / total)
    print()

    
###############################################################################
# Algorithm2: Ward Linkage Hierarchical Clustering
###############################################################################

cols_to_norm = chi_square_features
df[cols_to_norm] = df[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))

# DB Index Plot
print('Generating DB Index Plot....')
X_plot, Y_plot = [], []
for num_clusters in range(4, 20):
    cluster = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='ward')
    cluster.fit_predict(df[cols_to_norm])
    df = df.assign(labels=cluster.labels_)
    
    X_plot.append(num_clusters)
    score = davies_bouldin_score(df[cols_to_norm].copy(), cluster.labels_)
    print('Processed', num_clusters, 'clusters.')
    Y_plot.append(score)
plt.clf(); plt.plot(X_plot, Y_plot)
plt.ylabel('DB Index'); plt.xlabel('No. of clusters')
plt.savefig('6_chi_ward_dbindex.svg')
print('Generated DB Index Plot.')
Y_plot_sorted, X_plot_sorted  = zip(*sorted(zip(Y_plot, X_plot)))
print('Optimal Clusters according to DB Index:', X_plot_sorted[0])

for num_clusters in [4, 8]:
    cluster = AgglomerativeClustering(n_clusters=num_clusters, affinity='euclidean', linkage='ward')
    cluster.fit_predict(df[cols_to_norm])
    df = df.assign(labels=cluster.labels_)

    correct, total = 0, 0
    for cluster in range(num_clusters):
        cluster_df = df[df['labels'] == cluster]
        print('Cluster #', cluster, ', No of items in cluster:', len(cluster_df))

        Malware_percent = 100*len(cluster_df[cluster_df['binarylabel'] == 1]) / len(cluster_df)
        print('Malware Percentage:', Malware_percent)

        if(Malware_percent >= 50):
            correct += len(cluster_df[cluster_df['binarylabel'] == 1])
        else:
            correct += len(cluster_df[cluster_df['binarylabel'] == 0])
        total += len(cluster_df)

    for s in ['family', 'goal']:
        fig = plt.figure(figsize=(12, 6))
        for cluster in range(num_clusters):
            cluster_df = df[df['labels'] == cluster]
            if(num_clusters == 4): ax = fig.add_subplot(1, 4, cluster + 1)
            if(num_clusters == 8): ax = fig.add_subplot(2, 4, cluster + 1)
            ax = cluster_df[s].value_counts().plot(kind='pie', legend = True, labels = None, fontsize = 10)
            ax.legend(labels = cluster_df[s].value_counts().index, fontsize = 7)
        fig.savefig('ward_' + s + str(num_clusters) + '.svg')
        plt.clf()

    print("ACCURACY (MALWARE vs. NORMAL): ", 100 * correct / total)
    print()