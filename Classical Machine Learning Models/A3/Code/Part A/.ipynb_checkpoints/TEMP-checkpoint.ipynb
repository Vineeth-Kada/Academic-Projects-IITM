{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ead5d46f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../sharedFunctions.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 178>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m         log_likelihood \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(prob_block \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m500\u001b[39m))\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood\n\u001b[0;32m--> 178\u001b[0m exec(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../sharedFunctions.py\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mread())\n\u001b[1;32m    180\u001b[0m trainData \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    181\u001b[0m classList \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoast\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforest\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhighway\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmountain\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopencountry\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../sharedFunctions.py'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import DetCurveDisplay, ConfusionMatrixDisplay, confusion_matrix\n",
    "from math import sqrt\n",
    "import math\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from numba import njit\n",
    "import numba as nb\n",
    "\n",
    "# K - Means\n",
    "@njit\n",
    "def kMeans(X, K, k_iterations):\n",
    "    N = len(X)\n",
    "    D = X[0].shape[0]\n",
    "    \n",
    "    mu = [ X[i] for i in range(K) ]\n",
    "    cls = [ i for i in range(N) ]\n",
    "    \n",
    "    for _ in range(k_iterations):\n",
    "\n",
    "        # Assign Data points\n",
    "        for j in range(N):\n",
    "            mn = 0.0\n",
    "            currCls = 0\n",
    "            for k in range(K):\n",
    "                currDist = np.linalg.norm(mu[k] - X[j])\n",
    "                if(k == 0 or currDist < mn):\n",
    "                    mn = currDist\n",
    "                    currCls = k\n",
    "            cls[j] = currCls\n",
    "        \n",
    "        mu = [ np.zeros(D, dtype = np.float64) for k in range(K) ]\n",
    "        cnt = [ 0 for k in range(K) ]\n",
    "        for i in range(N):\n",
    "            mu[cls[i]] += X[i]\n",
    "            cnt[cls[i]] += 1\n",
    "        \n",
    "        for i in range(K):\n",
    "            mu[i] /= cnt[i]\n",
    "        \n",
    "    return cls, mu\n",
    "\n",
    "\n",
    "# GMM EM Algorithm\n",
    "@njit\n",
    "def my_mvn(mu, sigma, X):\n",
    "    D = sigma.shape[0]\n",
    "    det = np.linalg.det(sigma)\n",
    "    inv = np.linalg.inv(sigma)\n",
    "    \n",
    "    const = 1.0 / ((2.0 * math.pi) ** (D/2.0)) / (det ** 0.5)\n",
    "    exp = np.exp(-0.5 * ((X-mu).T @ inv @ (X-mu)))\n",
    "\n",
    "    return const * exp\n",
    "\n",
    "# E Step\n",
    "# Output: gamma\n",
    "@njit\n",
    "def e_step(pi, mu, sigma, X):\n",
    "    N = len(X)\n",
    "    K = len(mu)\n",
    "    D = X[0].shape[0]\n",
    "    \n",
    "    gamma = np.zeros((N, K), dtype = np.float64)\n",
    "    for n in range(N):\n",
    "        denom = 0.0\n",
    "        for j in range(K):\n",
    "            denom += pi[j] * my_mvn(mu[j],sigma[j], X[n])\n",
    "        for k in range(K):\n",
    "            gamma[n][k] = pi[k] * my_mvn(mu[k],sigma[k],X[n]) / denom\n",
    "            \n",
    "    return gamma\n",
    "\n",
    "# M Step\n",
    "# Input:\n",
    "    # gamma - 2D numpy array N * K => N points, K mixtures\n",
    "    # x - N length list of numpy arrays of dim([D, 1]) => N points, D features\n",
    "# Output:\n",
    "    # theta_new = [pi, mu, sigma]\n",
    "@njit\n",
    "def m_step(gamma, X):\n",
    "    N = gamma.shape[0]\n",
    "    K = gamma.shape[1]\n",
    "    D = X[0].shape[0]\n",
    "    \n",
    "    # Compute Nk for every class\n",
    "    Nk = np.zeros(K, dtype = np.float64)\n",
    "    for k in range(K):\n",
    "        Nk[k] = np.sum(gamma[:, k])\n",
    "\n",
    "    # Compute pi\n",
    "    pi = Nk / N\n",
    "\n",
    "    # Compute mu\n",
    "    mu = [ np.zeros(D, dtype = np.float64) for k in range(K) ]\n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            mu[k] += gamma[n][k] * X[n]\n",
    "        mu[k] /= Nk[k]\n",
    "        \n",
    "    # Compute sigma\n",
    "    sigma = [ np.zeros((D, D), dtype = np.float64) for k in range(K) ]\n",
    "    for k in range(K):\n",
    "        for n in range(N):\n",
    "            sigma[k] += gamma[n][k] * np.outer(X[n] - mu[k], X[n] - mu[k])\n",
    "        sigma[k] /= Nk[k]\n",
    "    \n",
    "    return pi, mu, sigma\n",
    "\n",
    "# GMM\n",
    "@njit\n",
    "def GMM(X, K, iterations, k_iterations):\n",
    "    N = len(X)\n",
    "    D = X[0].shape[0]\n",
    "    \n",
    "    # Initialise pi, mu, sigma using k-Means\n",
    "    cls, mu = kMeans(nb.typed.List(X), K , k_iterations)\n",
    "    print(\"K-Means Initialisation Done\")\n",
    "    pi = np.zeros(K, dtype = np.float64)\n",
    "    sigma = [ np.zeros((D, D), dtype = np.float64) for k in range(K) ]\n",
    "    Nk = np.zeros(K, dtype = np.float64)\n",
    "    \n",
    "    for i in range(N):\n",
    "        currCls = cls[i]\n",
    "        pi[currCls] += 1\n",
    "        Nk[currCls] += 1\n",
    "        sigma[currCls] += np.outer(X[i] - mu[currCls], X[i] - mu[currCls])\n",
    "        \n",
    "    for i in range(K):\n",
    "        pi[i] /= N\n",
    "        sigma[i] /= Nk[i]\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        gamma = e_step(nb.typed.List(pi), mu, sigma, nb.typed.List(X))\n",
    "        print(\"E STEP\")\n",
    "        \n",
    "        pi_new, mu_new, sigma_new = m_step(gamma, nb.typed.List(X))\n",
    "        print(\"M STEP\")\n",
    "        \n",
    "    return pi, mu, sigma\n",
    "\n",
    "# Convert normal matrix to diagonal matrix\n",
    "def make_dcov(cov):\n",
    "    dim = len(cov)\n",
    "    dcov = np.matrix(np.zeros(shape = (dim,dim)))\n",
    "    for i in range(dim) : dcov[i,i] = cov[i,i]\n",
    "    return dcov\n",
    "\n",
    "# Data Extraction from files\n",
    "def extractImgData(dir):\n",
    "    files = os.listdir(dir)\n",
    "    images = []\n",
    "    for file in files:\n",
    "        with open(dir + file, 'r') as f:\n",
    "            blocks = []\n",
    "            for line in f.readlines():\n",
    "                block = np.array(line.split(), dtype=np.float64)\n",
    "                blocks.append(block)\n",
    "            images.append(blocks)\n",
    "    return images\n",
    "\n",
    "\n",
    "# Calculate likelihood probability value for given image\n",
    "def log_likelihood(image,pis,means,covs,K):\n",
    "    log_likelihood = 0.0\n",
    "    for block in image:\n",
    "        prob_block = 0.0\n",
    "        for i in range(K):\n",
    "            mvn_out = my_mvn(means[i],covs[i], block)\n",
    "            prob_block += pis[i] * mvn_out\n",
    "        log_likelihood += np.log(prob_block + np.exp(-500))\n",
    "    return log_likelihood\n",
    "\n",
    "\n",
    "exec(open(\"../../sharedFunctions.py\").read())\n",
    "\n",
    "trainData = []\n",
    "classList = ['coast', 'forest', 'highway', 'mountain', 'opencountry']\n",
    "nClasses_Real = len(classList)\n",
    "\n",
    "for cls in classList:\n",
    "    images = extractImgData('RealData/' + cls + '/train/')\n",
    "    trainData.append(images)\n",
    "    \n",
    "# Normalisation\n",
    "# Step1: Find Mean\n",
    "allBlocks = []\n",
    "Dim = 23\n",
    "mean = np.zeros(23, dtype = np.float64)\n",
    "cnt_train1 = 0\n",
    "for i in range(nClasses_Real):\n",
    "    for image in trainData[i]:\n",
    "        for block in image:\n",
    "            mean += block\n",
    "            cnt_train1 += 1\n",
    "            allBlocks.append(block)\n",
    "mean /= cnt_train1\n",
    "\n",
    "# Step2: Subtract Mean & Find range\n",
    "mn = np.array([float('inf') for i in range(Dim)])\n",
    "mx = np.array([float('-inf') for i in range(Dim)])\n",
    "for block in allBlocks:\n",
    "    block = block - mean\n",
    "    mn = np.minimum(mn, block)\n",
    "    mx = np.maximum(mx, block)\n",
    "\n",
    "# Step3: Modify original data\n",
    "mult_factor = 100\n",
    "for cls in range(len(classList)):\n",
    "    for img_idx in range(len(trainData[cls])):\n",
    "        for blk_idx in range(len(trainData[cls][img_idx])):\n",
    "            trainData[cls][img_idx][blk_idx] -= mean\n",
    "            trainData[cls][img_idx][blk_idx] /= (mx - mn) / mult_factor\n",
    "\n",
    "X_dev = []\n",
    "nTests = 0\n",
    "groundtruth_dev = []\n",
    "for i in range(len(classList)):\n",
    "    cls = classList[i]\n",
    "    images = extractImgData('RealData/' + cls + '/dev/')\n",
    "    for image in images:\n",
    "        for blk_idx in range(len(image)):\n",
    "            image[blk_idx] -= mean\n",
    "            image[blk_idx] /= (mx - mn) / mult_factor\n",
    "        nTests += 1\n",
    "        X_dev.append(image)\n",
    "        groundtruth_dev.append(i)\n",
    "\n",
    "\n",
    "gmm_all_pis = []\n",
    "gmm_all_means = []\n",
    "gmm_all_covs = []\n",
    "gmm_all_dcovs = []\n",
    "\n",
    "# K_list = [5, 12, 16]\n",
    "K_list = [2, 2]\n",
    "for K in K_list:\n",
    "    all_pis = []\n",
    "    all_means = []\n",
    "    all_covs = []\n",
    "    all_dcovs = []\n",
    "\n",
    "    for c in range(nClasses_Real):\n",
    "        X = []\n",
    "        for image in trainData[c]:\n",
    "            for block in image:\n",
    "                X.append(block)\n",
    "#         pis,means,covs = GMM(nb.typed.List(X),K,7,20)\n",
    "        pis,means,covs = GMM(nb.typed.List(X),K,2,10)\n",
    "        dcovs = []\n",
    "        for cov in covs:dcovs.append(make_dcov(cov))\n",
    "        all_pis.append(pis)\n",
    "        all_means.append(means)\n",
    "        all_covs.append(covs)\n",
    "        all_dcovs.append(dcovs)\n",
    "\n",
    "    gmm_all_pis.append(all_pis)\n",
    "    gmm_all_means.append(all_means)\n",
    "    gmm_all_covs.append(all_covs)\n",
    "    gmm_all_dcovs.append(all_dcovs)\n",
    "\n",
    "dir_path = 'RealData_Results/RD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e500c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" Confusion Matrix \"\"\"\n",
    "for idx in range(len(K_list)):\n",
    "    K = K_list[idx]\n",
    "\n",
    "    all_pis = gmm_all_pis[idx]\n",
    "    all_means = gmm_all_means[idx]\n",
    "    all_covs = gmm_all_covs[idx]\n",
    "    \n",
    "    all_likelihood_dev = [[] for c in range(nClasses_Real)]\n",
    "    all_priors_dev = [1 / nClasses_Real for c in range(nClasses_Real)]\n",
    "\n",
    "    pred_class = []\n",
    "    cnt, accuracy = 0, 0\n",
    "    for image in X_dev:\n",
    "        LL = np.zeros(nClasses_Real)\n",
    "        for c in range(nClasses_Real):\n",
    "            LL[c] = log_likelihood(image,all_pis[c],all_means[c],all_covs[c],K)\n",
    "        trueCls, predCls = groundtruth_dev[cnt], np.argmax(LL)\n",
    "        pred_class.append(predCls)\n",
    "        if(trueCls == predCls): accuracy += 1\n",
    "        cnt += 1\n",
    "\n",
    "    ConfusionMatrixDisplay.from_predictions(groundtruth_dev, pred_class, display_labels=classList, xticks_rotation=45).plot()\n",
    "    plt.title('Confusion Matrix:(DEV)')\n",
    "    plt.savefig(dir_path + 'CMat' + str(K) + '.svg')\n",
    "    plt.clf()\n",
    "    print('*' * 25); print(accuracy / cnt * 100); print('*' * 25);\n",
    "\n",
    "\"\"\" ROC PLOTS \"\"\"\n",
    "ROC_legend = []\n",
    "for idx in range(len(K_list)):\n",
    "    K = K_list[idx]\n",
    "\n",
    "    all_pis = gmm_all_pis[idx]\n",
    "    all_means = gmm_all_means[idx]\n",
    "    all_covs = gmm_all_covs[idx]\n",
    "    all_dcovs = gmm_all_dcovs[idx]\n",
    "    \n",
    "    all_likelihood_dev = [[] for c in range(nClasses_Real)]\n",
    "    all_priors_dev = [1 / nClasses_Real for c in range(nClasses_Real)]\n",
    "    for c in range(nClasses_Real):\n",
    "        for image in X_dev:\n",
    "            all_likelihood_dev[c].append(log_likelihood(image,all_pis[c],all_means[c],all_covs[c],K))\n",
    "    ROC(all_likelihood_dev,all_priors_dev,nTests,nClasses_Real,groundtruth_dev)\n",
    "    legend.append('Normal K=' + str(K))\n",
    "    \n",
    "    all_likelihood_dev = [[] for c in range(nClasses_Real)]\n",
    "    all_priors_dev = [1 / nClasses_Real for c in range(nClasses_Real)]\n",
    "    for c in range(nClasses_Real):\n",
    "        for image in X_dev:\n",
    "            all_likelihood_dev[c].append(log_likelihood(image,all_pis[c],all_means[c],all_dcovs[c],K))\n",
    "    ROC(all_likelihood_dev,all_priors_dev,nTests,nClasses_Real,groundtruth_dev)\n",
    "    legend.append('Diagonal K=' + str(K))\n",
    "\n",
    "plt.xlabel('FPR'); plt.ylabel('TPR')\n",
    "plt.legend(legend)\n",
    "plt.title('ROC Curves for GMM with different K')\n",
    "plt.savefig(dir_path + '_ROC.svg')\n",
    "plt.clf()\n",
    "\n",
    "ax = plt.gca()\n",
    "for idx in range(len(K_list)):\n",
    "    K = K_list[idx]\n",
    "\n",
    "    all_pis = gmm_all_pis[idx]\n",
    "    all_means = gmm_all_means[idx]\n",
    "    all_covs = gmm_all_covs[idx]\n",
    "    \n",
    "    all_likelihood_dev = [[] for n in range(nClasses_Real)]\n",
    "    all_priors_dev = [1 / nClasses_Real for c in range(nClasses_Real)]\n",
    "    for c in range(nClasses_Real):\n",
    "        for image in X_dev:\n",
    "            all_likelihood_dev[c].append(log_likelihood(image,all_pis[c],all_means[c],all_covs[c],K))\n",
    "    FPR,FNR = DET(all_likelihood_dev,all_priors_dev,nTests,nClasses_Real,groundtruth_dev)\n",
    "    DetCurveDisplay(fpr = FPR, fnr = FNR, estimator_name = 'Normal K=' + str(K)).plot(ax)\n",
    "    \n",
    "    all_likelihood_dev = [[] for c in range(nClasses_Real)]\n",
    "    all_priors_dev = [1 / nClasses_Real for c in range(nClasses_Real)]\n",
    "    for c in range(nClasses_Real):\n",
    "        for image in X_dev:\n",
    "            all_likelihood_dev[c].append(log_likelihood(image,all_pis[c],all_means[c],all_dcovs[c],K))\n",
    "    FPR,FNR = DET(all_likelihood_dev,all_priors_dev,nTests,nClasses_Real,groundtruth_dev)\n",
    "    DetCurveDisplay(fpr = FPR, fnr = FNR, estimator_name = 'Diagonal K=' + str(K)).plot(ax)\n",
    "\n",
    "plt.title('DET Curves for GMM with different K')\n",
    "plt.savefig(dir_path + 'DET.svg')\n",
    "plt.clf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
